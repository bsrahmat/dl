{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be working with some California Census Data, we'll be trying to use various features of an individual to predict what class of income they belogn in (>50k or <=50k). \n",
    "\n",
    "Here is some information about the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Column Name</th>\n",
    "<th>Type</th>\n",
    "<th>Description</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>age</td>\n",
    "<td>Continuous</td>\n",
    "<td>The age of the individual</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>workclass</td>\n",
    "<td>Categorical</td>\n",
    "<td>The type of employer the  individual has (government,  military, private, etc.).</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>fnlwgt</td>\n",
    "<td>Continuous</td>\n",
    "<td>The number of people the census  takers believe that observation  represents (sample weight). This  variable will not be used.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>education</td>\n",
    "<td>Categorical</td>\n",
    "<td>The highest level of education  achieved for that individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>education_num</td>\n",
    "<td>Continuous</td>\n",
    "<td>The highest level of education in  numerical form.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>marital_status</td>\n",
    "<td>Categorical</td>\n",
    "<td>Marital status of the individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>occupation</td>\n",
    "<td>Categorical</td>\n",
    "<td>The occupation of the individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>relationship</td>\n",
    "<td>Categorical</td>\n",
    "<td>Wife, Own-child, Husband,  Not-in-family, Other-relative,  Unmarried.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>race</td>\n",
    "<td>Categorical</td>\n",
    "<td>White, Asian-Pac-Islander,  Amer-Indian-Eskimo, Other, Black.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>gender</td>\n",
    "<td>Categorical</td>\n",
    "<td>Female, Male.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>capital_gain</td>\n",
    "<td>Continuous</td>\n",
    "<td>Capital gains recorded.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>capital_loss</td>\n",
    "<td>Continuous</td>\n",
    "<td>Capital Losses recorded.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>hours_per_week</td>\n",
    "<td>Continuous</td>\n",
    "<td>Hours worked per week.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>native_country</td>\n",
    "<td>Categorical</td>\n",
    "<td>Country of origin of the  individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>income</td>\n",
    "<td>Categorical</td>\n",
    "<td>\"&gt;50K\" or \"&lt;=50K\", meaning  whether the person makes more  than \\$50,000 annually.</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow the Directions in Bold. If you get stuck, check out the solutions lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Read in the census_data.csv data with pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "census = pd.read_csv(\"census_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country income_bracket  \n",
       "0             0              40   United-States          <=50K  \n",
       "1             0              13   United-States          <=50K  \n",
       "2             0              40   United-States          <=50K  \n",
       "3             0              40   United-States          <=50K  \n",
       "4             0              40            Cuba          <=50K  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** TensorFlow won't be able to understand strings as labels, you'll need to use pandas .apply() method to apply a custom function that converts them to 0s and 1s. This might be hard if you aren't very familiar with pandas, so feel free to take a peek at the solutions for this part.**\n",
    "\n",
    "** Convert the Label column to 0s and 1s instead of strings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census['income_bracket'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_fix(label):\n",
    "    if label==' <=50K':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "census['income_bracket'] = census['income_bracket'].apply(label_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cool Alternative\n",
    "# lambda label:int(label==' <=50k')\n",
    "\n",
    "# census['income_bracket'].apply(lambda label: int(label==' <=50K'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a Train Test Split on the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = census.drop('income_bracket',axis=1)\n",
    "y_labels = census['income_bracket']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data,y_labels,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Feature Columns for tf.esitmator\n",
    "\n",
    "** Take note of categorical vs continuous values! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'education', 'education_num', 'marital_status',\n",
       "       'occupation', 'relationship', 'race', 'gender', 'capital_gain',\n",
       "       'capital_loss', 'hours_per_week', 'native_country', 'income_bracket'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import Tensorflow **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Create the tf.feature_columns for the categorical values. Use vocabulary lists or just use hash buckets. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = tf.feature_column.categorical_column_with_vocabulary_list(\"gender\", [\"Female\", \"Male\"])\n",
    "occupation = tf.feature_column.categorical_column_with_hash_bucket(\"occupation\", hash_bucket_size=1000)\n",
    "marital_status = tf.feature_column.categorical_column_with_hash_bucket(\"marital_status\", hash_bucket_size=1000)\n",
    "relationship = tf.feature_column.categorical_column_with_hash_bucket(\"relationship\", hash_bucket_size=1000)\n",
    "education = tf.feature_column.categorical_column_with_hash_bucket(\"education\", hash_bucket_size=1000)\n",
    "workclass = tf.feature_column.categorical_column_with_hash_bucket(\"workclass\", hash_bucket_size=1000)\n",
    "native_country = tf.feature_column.categorical_column_with_hash_bucket(\"native_country\", hash_bucket_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the continuous feature_columns for the continuous values using numeric_column **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = tf.feature_column.numeric_column(\"age\")\n",
    "education_num = tf.feature_column.numeric_column(\"education_num\")\n",
    "capital_gain = tf.feature_column.numeric_column(\"capital_gain\")\n",
    "capital_loss = tf.feature_column.numeric_column(\"capital_loss\")\n",
    "hours_per_week = tf.feature_column.numeric_column(\"hours_per_week\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Put all these variables into a single list with the variable name feat_cols **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [gender,occupation,marital_status,relationship,education,workclass,native_country,\n",
    "            age,education_num,capital_gain,capital_loss,hours_per_week]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Input Function\n",
    "\n",
    "** Batch_size is up to you. But do make sure to shuffle!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\basuki rahmat\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:63: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_func=tf.compat.v1.estimator.inputs.pandas_input_fn(x=X_train,\n",
    "                                               y=y_train,\n",
    "                                               batch_size=100,\n",
    "                                               num_epochs=None,\n",
    "                                               shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create your model with tf.estimator\n",
    "\n",
    "**Create a LinearClassifier.(If you want to use a DNNClassifier, keep in mind you'll need to create embedded columns out of the cateogrical feature that use strings, check out the previous lecture on this for more info.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\BASUKI~1\\AppData\\Local\\Temp\\tmp_4vb7wco\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\BASUKI~1\\\\AppData\\\\Local\\\\Temp\\\\tmp_4vb7wco', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.LinearClassifier(feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train your model on the data, for at least 5000 steps. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\basuki rahmat\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:235: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From c:\\users\\basuki rahmat\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:60: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From c:\\users\\basuki rahmat\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:491: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\basuki rahmat\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\basuki rahmat\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\ftrl.py:133: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From c:\\users\\basuki rahmat\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:906: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\BASUKI~1\\AppData\\Local\\Temp\\tmp_4vb7wco\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.6931472, step = 0\n",
      "INFO:tensorflow:global_step/sec: 121.582\n",
      "INFO:tensorflow:loss = 15.61515, step = 100 (0.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.989\n",
      "INFO:tensorflow:loss = 0.8607193, step = 200 (0.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.446\n",
      "INFO:tensorflow:loss = 2.8373232, step = 300 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.65\n",
      "INFO:tensorflow:loss = 1.3766807, step = 400 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.214\n",
      "INFO:tensorflow:loss = 1.5062696, step = 500 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.874\n",
      "INFO:tensorflow:loss = 0.5756204, step = 600 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.5\n",
      "INFO:tensorflow:loss = 3.4756303, step = 700 (0.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.873\n",
      "INFO:tensorflow:loss = 3.7765253, step = 800 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.09\n",
      "INFO:tensorflow:loss = 1.0370618, step = 900 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.384\n",
      "INFO:tensorflow:loss = 1.9098103, step = 1000 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.365\n",
      "INFO:tensorflow:loss = 1.0792358, step = 1100 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.931\n",
      "INFO:tensorflow:loss = 0.530363, step = 1200 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.401\n",
      "INFO:tensorflow:loss = 1.725617, step = 1300 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.972\n",
      "INFO:tensorflow:loss = 0.34996226, step = 1400 (0.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.975\n",
      "INFO:tensorflow:loss = 1.2139788, step = 1500 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.988\n",
      "INFO:tensorflow:loss = 1.06058, step = 1600 (0.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.889\n",
      "INFO:tensorflow:loss = 1.0882697, step = 1700 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.445\n",
      "INFO:tensorflow:loss = 0.45284736, step = 1800 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.536\n",
      "INFO:tensorflow:loss = 0.56918466, step = 1900 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.414\n",
      "INFO:tensorflow:loss = 0.3624144, step = 2000 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.499\n",
      "INFO:tensorflow:loss = 0.37715492, step = 2100 (0.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.351\n",
      "INFO:tensorflow:loss = 2.8870347, step = 2200 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.931\n",
      "INFO:tensorflow:loss = 1.0812879, step = 2300 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.028\n",
      "INFO:tensorflow:loss = 1.1800543, step = 2400 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.624\n",
      "INFO:tensorflow:loss = 0.3163201, step = 2500 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.898\n",
      "INFO:tensorflow:loss = 1.8307595, step = 2600 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.953\n",
      "INFO:tensorflow:loss = 0.30466342, step = 2700 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.887\n",
      "INFO:tensorflow:loss = 3.1679397, step = 2800 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.874\n",
      "INFO:tensorflow:loss = 1.2411953, step = 2900 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.852\n",
      "INFO:tensorflow:loss = 0.6254072, step = 3000 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.5\n",
      "INFO:tensorflow:loss = 0.25612473, step = 3100 (0.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.384\n",
      "INFO:tensorflow:loss = 0.33861697, step = 3200 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.888\n",
      "INFO:tensorflow:loss = 1.0211079, step = 3300 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.264\n",
      "INFO:tensorflow:loss = 0.5451206, step = 3400 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.463\n",
      "INFO:tensorflow:loss = 0.31936252, step = 3500 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.958\n",
      "INFO:tensorflow:loss = 0.36486736, step = 3600 (0.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.887\n",
      "INFO:tensorflow:loss = 0.42902905, step = 3700 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.312\n",
      "INFO:tensorflow:loss = 1.2488358, step = 3800 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.625\n",
      "INFO:tensorflow:loss = 2.1706705, step = 3900 (0.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.401\n",
      "INFO:tensorflow:loss = 0.5996655, step = 4000 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.739\n",
      "INFO:tensorflow:loss = 2.5515745, step = 4100 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.536\n",
      "INFO:tensorflow:loss = 0.3444379, step = 4200 (0.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.792\n",
      "INFO:tensorflow:loss = 0.44067124, step = 4300 (0.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.732\n",
      "INFO:tensorflow:loss = 1.4022837, step = 4400 (0.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.324\n",
      "INFO:tensorflow:loss = 1.6057278, step = 4500 (0.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.053\n",
      "INFO:tensorflow:loss = 0.38679302, step = 4600 (0.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.382\n",
      "INFO:tensorflow:loss = 0.40766352, step = 4700 (0.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.974\n",
      "INFO:tensorflow:loss = 0.28109312, step = 4800 (0.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.624\n",
      "INFO:tensorflow:loss = 1.2986609, step = 4900 (0.436 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\BASUKI~1\\AppData\\Local\\Temp\\tmp_4vb7wco\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.39193258.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearClassifierV2 at 0x221a1c89970>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=input_func,steps=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "** Create a prediction input function. Remember to only supprt X_test data and keep shuffle=False. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(x=X_test,batch_size=len(X_test),shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Use model.predict() and pass in your input function. This will produce a generator of predictions, which you can then transform into a list, with list() **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\BASUKI~1\\AppData\\Local\\Temp\\tmp_4vb7wco\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions = list(model.predict(input_fn=pred_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Each item in your list will look like this: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logits': array([-1.0177872], dtype=float32),\n",
       " 'logistic': array([0.26545867], dtype=float32),\n",
       " 'probabilities': array([0.73454136, 0.26545864], dtype=float32),\n",
       " 'class_ids': array([0], dtype=int64),\n",
       " 'classes': array([b'0'], dtype=object),\n",
       " 'all_class_ids': array([0, 1]),\n",
       " 'all_classes': array([b'0', b'1'], dtype=object)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a list of only the class_ids key values from the prediction list of dictionaries, these are the predictions you will use to compare against the real y_test values. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "for pred in predictions:\n",
    "    final_preds.append(pred['class_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import classification_report from sklearn.metrics and then see if you can figure out how to use it to easily get a full report of your model's performance on the test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91      7436\n",
      "           1       0.73      0.61      0.66      2333\n",
      "\n",
      "    accuracy                           0.85      9769\n",
      "   macro avg       0.80      0.77      0.78      9769\n",
      "weighted avg       0.85      0.85      0.85      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,final_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_input_func = tf.compat.v1.estimator.inputs.pandas_input_fn(x=X_test,y=y_test,batch_size=len(X_test),shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91      7436\n",
      "           1       0.73      0.61      0.66      2333\n",
      "\n",
      "    accuracy                           0.85      9769\n",
      "   macro avg       0.80      0.77      0.78      9769\n",
      "weighted avg       0.85      0.85      0.85      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_test,final_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\basuki rahmat\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-03-16T14:05:20Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\BASUKI~1\\AppData\\Local\\Temp\\tmp_4vb7wco\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 1.57170s\n",
      "INFO:tensorflow:Finished evaluation at 2021-03-16-14:05:21\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.85167366, accuracy_baseline = 0.7611833, auc = 0.9011493, auc_precision_recall = 0.75569725, average_loss = 0.32912555, global_step = 5000, label/mean = 0.23881666, loss = 0.32912555, precision = 0.7268994, prediction/mean = 0.23063838, recall = 0.60694385\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: C:\\Users\\BASUKI~1\\AppData\\Local\\Temp\\tmp_4vb7wco\\model.ckpt-5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.85167366,\n",
       " 'accuracy_baseline': 0.7611833,\n",
       " 'auc': 0.9011493,\n",
       " 'auc_precision_recall': 0.75569725,\n",
       " 'average_loss': 0.32912555,\n",
       " 'label/mean': 0.23881666,\n",
       " 'loss': 0.32912555,\n",
       " 'precision': 0.7268994,\n",
       " 'prediction/mean': 0.23063838,\n",
       " 'recall': 0.60694385,\n",
       " 'global_step': 5000}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(eval_input_func)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
